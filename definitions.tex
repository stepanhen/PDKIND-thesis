\chapter{Background}

\newtheorem{definition}{Definition}
\section{Transition System}
\noindent Transition systems provide a framework for modeling how systems change over time through state transitions. They are extensively used in formal methods, program analysis, and verification. Transition systems consist of a set of initial states, a set of states, and a transition relation that defines the evolution of states. Transition systems are used as an abstraction in computer science and software verification to solve several problems, including the Constrained Horn Clause's (CHC) satisfiability. By offering a formal method of representing the behavior of a computer system or an abstract computing device, they make it easier to analyze and verify properties. We will introduce the basic ideas of transition systems in this chapter, which will help us understand the following chapters.

\begin{definition}
    \textbf{Transition System \cite{7886665}:}
    A transition system is a 4-tuple ($S$, $\mathcal{F}$, $\mathcal{T}$, $\mathcal{I}$), where:
    \begin{itemize}
        \item \( S \) is a finite set of state variables \( \vec{x} \). Each \( x \in \vec{x} \) has a primed version \( x' \) representing its value in the next state. A \textbf{state} \( s \) is a valuation over \( \vec{x} \) that assigns a value \( s(x) \) to each \( x \in \vec{x} \).
        \item \( \mathcal{F} \) is a set of quantifier-free formulas, where each \( F(\vec{x}) \in \mathcal{F} \) is a \textbf{state formula} that holds in a state \( s \) if \( s \models F \).
        \item \( \mathcal{T} \) is a set of quantifier-free formulas, where each \( T(\vec{x}, \vec{x}') \in \mathcal{T} \) is a \textbf{transition formula} describing valid transitions between states. A transition from state \( s \) to \( s' \) is allowed if \( (s, s') \models T \) for some \( T \in \mathcal{T} \).
        \item \( \mathcal{I} \) is a set of formulas, where each \( I(\vec{x}) \in \mathcal{I} \) is a \textbf{state formula} describing initial states. A state \( s \) is an initial state if \( s \models I \).
    \end{itemize}
\end{definition}

\begin{definition}
    \textbf{Successor \cite{7886665}:}
    State $s$ has a successor $s'$, when $T(s(\vec{x}), s'(\vec{x}'))$ is true.
\end{definition}

\begin{definition}
    \textbf{k-Reachability \cite{7886665}:}
    State $s$ is k-reachable if there exists a sequence
    $I = s_0, s_1, s_2, \ldots, s_k = s$, where each $s_{i+1}$ is a successor of $s_i$.
\end{definition}

\section{Safety of Transition System}


\noindent An essential concept in the analysis of transition systems is safety. We
consider a transition system to be safe if it never reaches an
unsafe state during its execution, where an unsafe state is one in which
the desired property is violated. This notion of safety is crucial for
verifying the correctness of programs and systems modeled by transition
systems.

\begin{definition}\textbf{Safety Property:} A property $P$ is called a \textbf{safety
property} if it ensures that “nothing bad will ever happen” during the
execution of the system. Formally, given a transition system $(S, \mathcal{F},
T, I)$ and a property $P$ (a state formula that can be evaluated on each
state), we say $P$ is a safety property if for every reachable state $s \in S$,
$P(s)$ is true. Equivalently, the system never reaches a state where $P(s)$ is
false (such a state is considered unsafe). \end{definition}

\begin{definition}\textbf{Invariant \cite{7886665}:} An \textbf{invariant} is a property
that holds in all reachable states of a transition system. Formally, for a
transition system $(S, \mathcal{F}, T, I)$, a state formula $I$ is an invariant if
every reachable state $s \in S$ satisfies $I(s)$. \end{definition}

\noindent Safety properties can often
be expressed as invariants, since they require that the system never enters an
unsafe state.

\vspace{\baselineskip}
\noindent\textbf{Verifying Safety.} To verify whether a transition system satisfies a
given safety property $P$, we must check that all reachable states of the
system satisfy $P$. There are several approaches to perform this verification:


\begin{itemize}
\item\textbf{Explicit State Exploration.} 

This technique enumerates all reachable states of the system and checks whether
the safety property holds in each of them. While simple and complete for finite
systems, it quickly becomes infeasible due to the state explosion problem.
Tools like SPIN\cite{588521} apply optimizations to mitigate this.

\item\textbf{Bounded Model Checking (BMC).} 

BMC checks whether a counterexample of length \( k \) exists by unrolling the
transition system \( k \) steps and using a SAT/SMT solver to find violations.
If no counterexample is found, the property holds up to depth \( k \), but this
alone is not enough to prove the property.

To prove unbounded safety, BMC is often combined with k-induction\ref{Def:kind}. This method verifies that the property holds for all states reachable within \( k \) steps and 
that if the property holds for \( k \) steps, it holds for the \( k+1 \)-th as well.
If both checks succeed, the property is proven for all executions.

\item\textbf{Inductive Invariant Checking.} This method tries to find an invariant \( \mathit{Inv}(x) \) that holds initially, is preserved by transitions, and implies the safety property.

If such an invariant is found, it proves the property. Algorithms like IC3\cite{6148908} automatically construct inductive invariants. Many verification tools encode these problems as Constrained Horn Clauses (CHCs) and solve them using SMT-based solvers.
\end{itemize}

\noindent\textbf{Example:} Consider a transition system modeling a simple counter with state variable $x$ that starts at 0 and is incremented by 1 at each step. Formally, let the initial condition be $\mathcal{I}$ and the transition relation be $\mathcal{T}$. 

\begin{align*}
    \mathcal{I}&: x = 0 \\
    \mathcal{T}&: x' = x + 1
\end{align*}
Now suppose we have a safety property $P$ stating that “the counter never exceeds 10,” i.e., $P(s)$ is $(x \le 10)$ for a state $s$. In this system, $P$ is actually violated after few steps: for instance, after 11 transitions, the counter reaches a state where $x = 11$, which is an unsafe state since it does not satisfy $P$. We can illustrate how each verification technique would handle this scenario.

An explicit state exploration would enumerate states $x = 0, 1, 2, \dots$ and eventually encounter $x = 11$, identifying it as a counterexample that violates the safety property. 

Using BMC, if we set the bound $k = 10$, the model checker will not find any violation since no state with $x>10$ is reachable within 10 steps. Increasing the bound to $k = 11$ will produce a counterexample trace $s_0 \to s_1 \to \cdots \to s_{11}$ where $s_0$ has $x=0$ and $s_{11}$ has $x=11$, demonstrating that an unsafe state is reachable. This shows that BMC can detect the error when the bound is sufficiently large, but it cannot conclude overall safety without considering an unbounded number of steps.

With inductive invariant checking, we would attempt to prove the property $x \le 10$ by induction. In this case, no suitable inductive invariant exists to prove $x \le 10$ for all reachable states because the property itself is false for reachable state $x=11$. The inductive step fails. As a result, the method reports that it cannot prove the property, effectively uncovering the same counterexample at the point where the induction fails.

Ensuring safety is critical for system reliability. By using the appropriate verification technique (or a combination of techniques), we can determine whether a system satisfies its safety properties or find counterexamples that demonstrate violations.


\section{Satisfiability Modulo Theories\cite{BarFT-SMTLIB}}
\noindent In logic and computer science, the Boolean satisfiability problem, also called SAT, is one of the most well-known problems. In 1971, it was proven to be the first NP-complete problem \cite{10.1145/800157.805047}. This greatly helped in the field of complexity theory by providing a tool for the classification of other computational problems. SAT is widely used, but there are cases where it is not possible to represent a problem using only the two Boolean values, true and false.

This led to the generalization of SAT to more complex formulas, including real numbers, integers, or even lists and other data structures. In other words, an SMT instance arises as a generalization of a SAT instance, where Boolean variables are replaced with predicates of some theory. Examples of such theories are uninterpreted functions (UF), arrays, linear arithmetic (LA), or, more specifically, linear real arithmetic (LRA), which we will focus on in the rest of this work.

SMT solvers are widely used in various fields, such as formal verification, model checking, program synthesis, and hardware verification. They are instrumental in solving real-world problems that involve reasoning over complex theories, such as reasoning about hardware designs, program correctness, and even automated theorem proving.

The concept of SMT was introduced in the late 1990s as a way to extend SAT to handle more expressive logical formulas. SMT solvers combine techniques from both SAT solving and decision procedures for various theories, making them more powerful and versatile than traditional SAT solvers.

Each theory in SMT corresponds to a set of logical rules and operations for a specific type of data. For instance, in the case of Linear Real Arithmetic (LRA), the theory defines operations and constraints over real numbers. SMT solvers then check the satisfiability of a formula under a combination of such theories, making it more expressive than just Boolean logic.

For example, consider a system where we need to check if there is an assignment of integer values $x$ and $y$ that satisfies the following conditions:
\begin{equation*}
    2x + y \geq 10 \land x - y = 3
\end{equation*}

A traditional SAT solver would not be able to handle this problem, as it involves arithmetic over integers. However, using the linear arithmetic (LA) theory, an SMT solver can quickly solve this problem.


To find a satisfying assignment, we solve the system:
\begin{align*}
x - y &= 3 \\
2x + y &\ge 10
\end{align*}
From the first equation, we isolate \( x \):
\[
x = y + 3
\]
Substitute into the second inequality:
\[
2(y + 3) + y \ge 10 \Rightarrow 2y + 6 + y \ge 10 \Rightarrow 3y \ge 4 \Rightarrow y \ge \frac{4}{3}
\]
Then 
\[ x = y + 3 \Rightarrow x \ge \frac{4}{3} + 3 = \frac{13}{3} \]
So any pair \( (x, y) \) such that \( y \ge \frac{4}{3} \) and \( x = y + 3 \) is a solution. For example:
\[
y = 2,\quad x = 5
\]
is a valid model:
\[
2 \cdot 5 + 2 = 12 \ge 10,\quad 5 - 2 = 3
\]


While SAT solvers are only used for assigning values for Boolean variables, SMT solvers work with more complex theories, allowing them to handle constraints over data types beyond just true or false values. This extension makes SMT a powerful tool for solving problems that SAT solvers cannot address.

\section{CHC Satisfiability}
\noindent Constrained Horn Clauses (CHCs)\cite{10.1007/978-3-031-13185-1_2} is a fragment of First Order Logic
modulo constraints that capture many program verification problems as
constraint solving.

\vspace{\baselineskip}\noindent
They extend Horn Clauses, which are logical formulas of the form:
\begin{equation*}
    P_{1} \land P_{2} \land \dots \land P_{n} \implies H
\end{equation*}
where $P_i$ are body literals and $H$ is the head of the clause.

\vspace{\baselineskip}
In CHCs, the literals in the body can include constraints in a first-order theory, such as linear arithmetics, boolean logic, etc.
Therefore, CHC is a formula of the form:
\begin{equation*}
    \phi \land P_{1} \land P_{2} \land \dots \land P_{n} \implies H
\end{equation*}
where $\phi$ is a constraint in the first order theory, $P_i$ and $H$ are uninterpreted predicates.

\vspace{\baselineskip}\noindent
A CHC is satisfiable if there exists an interpretation of the uninterpreted predciates $P_i$ and $H$ that is valid in the background theory.

The main advantage of CHC is that it separates the modeling
from solving by translating the program’s behavior and properties into
constrained language and then using a specialized CHC solver to solve various
verification tasks across programming languages by deciding the satisfiability
problem of a CHC system.

\vspace{\baselineskip}\noindent
For example, we consider a program with a loop:
\vspace{\baselineskip}
\begin{figure}[h]
    \begin{mdframed}
        \begin{lstlisting}
int i $\rightarrow$ 10;

while (x > 0) {
    x $\rightarrow$ x - 1;
}

assert (x >= 0);
        \end{lstlisting}
    \end{mdframed}
\end{figure}

\noindent We can encode the behavior and safety of this program in CHCs:

\noindent\vspace{\baselineskip}
\textbf{Initial clause:}
\begin{equation}
    x = 10 \implies P(x)
    \label{chc:init}
\end{equation}
\vspace{\baselineskip}
\textbf{Transition clause:}
\begin{equation}
     P(x) \land x > 0 \land x' = x - 1 \implies P(x')
    \label{chc:trans}
\end{equation}
\vspace{\baselineskip}
\textbf{Safety clause:}
\begin{equation}
    P(x) \land x < 0  \implies False
    \label{chc:safe}
\end{equation}

In this simple example, we encode the program using three CHC clauses. \eqref{chc:init} describes the initial state of the program and introduces an
uninterpreted predicate $P(x)$, which represents the loop invariant. \eqref{chc:trans} describes one step of the loop's transition: it checks if $x>0$
(the loop condition) and $P(x)$ (the invariant), then decrements $x$.
Satisfiability of the left-hand side of this clause implies that the invariant
$P(x')$ holds for the decremented value of $x$. Finally, \eqref{chc:safe}
checks the assertion condition. We verify the assertion by checking if its negation
leads to a contradiction. If the negation is satisfiable, it
implies a false state, indicating that the assertion does not hold.

In the previous example, we demonstrated how to encode a simple loop using
Constrained Horn Clauses (CHCs). This encoding process is not limited to simple
loops and can be extended to more complex and less deterministic loops. By
representing the loop’s initial state, transition, and termination conditions
as CHCs, we can analyze the program's behavior over a series of execution
steps. We can introduce a compact representation of a loop in CHCs as follows.

\vspace{\baselineskip}
\begin{equation}
    \begin{aligned}
        Init(V) &\implies Inv(V) \\
        Inv(V) \land Tr(V, V') &\implies Inv(V') \\
        Inv(V) \land Bad(V) &\implies False
    \end{aligned}
\end{equation}
This representation allows us to analyze the loop's behavior over a finite number of iterations. 
%To obtain a finite trace of the loop, we unroll it $k$ times, where $k$ is a finite number.
%\vspace{\baselineskip}
%\begin{equation}
%    Init(V) \land Tr(V, V^2) \dots \land Tr(V^{k-1}, V^k) \land Bad(V^k)
%\end{equation}
%This unrolled loop is known as a \textbf{Bounded Model Checking (BMC)} formula.
%By increasing $k$, we can evaluate more BMC formulas, which helps detect more system bugs. However, we must identify inductive invariants to prove that no bugs exist. In our work, we will leverage BMC formulas to discover
%these invariants.


\section{OpenSMT}
\noindent Golem uses OpenSMT\cite{10.1007/978-3-642-12002-2_12} as its underlying SMT solver to handle formulas that arise during CHC solving. OpenSMT supports several background theories and provides features like interpolation, which are necessary for some of the algorithms implemented in Golem. 

is an open-source SMT solver developed by the Formal Verification and Security Lab based at the University of Lugano. It includes a parser for SMT-LIB\cite{BarFT-SMTLIB} language, a state-of-the-art SAT-Solver, and a clean interface for new theory solvers, currently supporting various logics such as QF\_UF, QF\_LIA, QF\_LRA, and more. Currently, there is a second version OpenSMT2\cite{10.1007/978-3-319-40970-2_35}, which supports interpolation for propositional logic, QF\_UF, QF\_LRA, QF\_LIA, and QF\_IDL.

\section{Induction vs k-Induction}
\noindent The PDKind algorithm is a combination of IC3 and k-induction.
IC3\cite{6148908} is a commonly used method that uses induction to show a property is invariant by incrementally constructing an inductive strengthening of the property. PDKind \cite{7886665} breaks IC3 into modules, which allows replacing the induction method with k-induction.

We need to introduce two definitions to compare the relative strength of induction and k-induction. Let us have a transition system ($S$, $\mathcal{F}$, $\mathcal{T}$, $\mathcal{I}$).
\vspace{\baselineskip}
\begin{definition}
($\mathcal{F}$-Induction\cite{7886665}): Let $\mathcal{F}$ be a set of state formulas, where $P \in \mathcal{F}$. Then \( P \) is $\mathcal{F}$-inductive if:
\begin{align*}
    I(\vec{x})
    &\implies \mathcal{F}(\vec{x}), \hspace{5cm}&\text{(init)} \\
    \mathcal{F}(\vec{x}) \land T(\vec{x}, \vec{x}') &\implies P(\vec{x}'). \hspace{5cm}&\text{(cons)}
\end{align*}
If $\mathcal{F} = {P}$, we say that \( P \) is inductive,
\label{Def:ind}
\end{definition}

\vspace{\baselineskip}
\cite{7886665} states that if P is inductive, it is also invariant. However, invariants are generally not inductive. To prove that \( P \) is an invariant, we need to find a set of formulas $\mathcal{F}$ that includes \( P \) and is itself inductive. This set is also called the strengthening of \( P \). If such a strengthening exists, then \( P \) must be an invariant.

\vspace{\baselineskip}
\begin{definition}
($\mathcal{F}^k$-Induction\cite{7886665}):Let $\mathcal{F}$ be a set of state formulas, where $P \in \mathcal{F}$. Then \( P \) is $\mathcal{F}^k$-inductive if:

\begin{align*}
    I(\vec{x_0}) \land \bigwedge_{i = 0}^{l - 1}T(\vec{x_i}, \vec{x}_{i+1})
    &\implies \mathcal{F}(\vec{x_l}), \quad &\text{for } 0 \leq l < k \quad \text{(k-init)} \\
    \bigwedge_{i = 0}^{k - 1}(\mathcal{F}(\vec{x_i}) \land T(\vec{x_i}, \vec{x}_{i+1}))
    &\implies P(\vec{x_k}). \quad &\text{(k-cons)}
\end{align*}
If $\mathcal{F} = {P}$, we say that \( P \) is \( k \)-inductive.
\label{Def:kind}
\end{definition}
If we substitute \( k \) with 1 in k-induction definition\ref{Def:kind}, we can see that a property that is inductive is 1-inductive and also \( k \)-inductive for any \( k \). In the other direction, \cite{7886665} shows that if a property \( P \) is \( k \)-inductive and the logical theory allows quantifier elimination, then an inductive strengthening of \( P \) can be constructed by interpolation.

For theories that admit quantifier elimination, k-induction and induction have the same deductive power. However, \cite{Bjørner2015} shows that k-induction can yield more succinct strengthening. For other theories, such as Boolean logic or Linear arithmetic, k-induction may be exponentially more powerful than induction due to weaker interpolation.

\subsection*{Practical Effectiveness}
\noindent \cite{7886665} shows that k-Induction is effective, especially when combined with algorithms like IC3.
\cite{7886665} demonstrates the effectiveness of k-induction on an example. The same example is depicted in Figure \ref{ex:ind vs kind}.

\begin{figure}[h]
    \begin{mdframed}
        \begin{lstlisting}
Invariant Property P: a[0] == 0

Initial States:
i = 0
j = 0
a[0] = 0

Transition:
j = Random() mod (i+1)
i = i + 1 mod N
a[i] = a[j]
        \end{lstlisting}
        \caption{Induction vs K-induction example}\label{ex:ind vs kind}
    \end{mdframed}
\end{figure}

\vspace{\baselineskip}The example shows a transition system, where zeroes are written to an array in a circular manner. The goal is to prove that the property $a[0] == 0$ is true throughout the execution of the program.

\newpage
\vspace{\baselineskip}\noindent \textbf{Induction:}

\vspace{\baselineskip}\noindent To prove \( P \) using induction, we must show the following:
\begin{itemize}
    \item\textbf{Initial state}: \( P \) holds in the initial state. This is true since $a[0] = 0$
    \item\textbf{Inductive step}: If \( P \) holds in state \( k \), it must hold in state \( k + 1\)
\end{itemize}

Here induction fails because it only considers a single step, which doesn't guarantee that $a[j]$ is always defined correctly. Thus, the program could copy a value from an undefined location to $a[0]$, which could break the property.

\vspace{\baselineskip}\noindent \textbf{K-Induction:}

\vspace{\baselineskip}\noindent While induction attempts to prove \( P \) in a single step, k-induction considers a sequence of steps. In this case, choosing \( k = N + 1 \) allows the index \( i \) to cycle back to 0, covering a complete cycle of transitions.

Over these \( N+1 \) steps, every position in the array copies a zero from a previous index, eventually filling the entire array with zeros. This guarantees that \( a[0] = 0 \) always holds.
Thus, \( P \) is \( (N+1) \)-inductive.

\vspace{\baselineskip}This example illustrates how \( k \)-induction succeeds where simple induction fails, particularly in systems with state transitions that unfold over multiple steps.

%\section{SMT-LIB}
%\noindent SMT-LIB\cite{BarFT-SMTLIB} is an international initiative that provides standard descriptions of background theories used in SMT solvers and develops common input and output languages for SMT solvers. It offers a unified framework for the description of SMT problems.  Additionally, SMT-LIB maintains a library of input problems, or benchmarks, written in the SMT-LIB language to support the development of different SMT solvers.


%\begin{figure}[h]
%\begin{mdframed}
%\begin{lstlisting}[language=Lisp]
%; Integer arithmetic
%(set-logic QF_LIA)
%(declare-const x Int)
%(declare-const y Int)

%; Assertion
%(assert (= (- x y) (+ x (- y) 1)))

%; Check satisfiability
%(check-sat)

%(exit)
%\end{lstlisting}
%\end{mdframed}
%\caption{SMT-LIB input example}
%\end{figure}

%In the Figure \ref{ex:ind vs kind} we can see an example of the SMT-LIB input taken from the offical examples of SMT-LIB\cite{BarFT-SMTLIB} .\begin{itemize}
%\item Lines starting with ';' represent comments and are ommited.
%\item \textbf{(set-logic QF\_LIA)}: This command sets the logic to Quantifier-Free Linear Integer Arithmetic (QF\_LIA), which involves linear integer arithmetic expressions without quantifiers.
%\item \textbf{(declare-const x Int) and (declare-const y Int)}: These commands declare two integer constants x and y.
%\item \textbf{(assert (= (- x y) (+ x (- y) 1)))}: This assertion states that $x - y$ should be equal to $x - y + 1$
%\item \textbf{(check-sat)}: This command asks the SMT solver to check the satisfiability of the assertion.
%\item \textbf{(exit)}: This command exits the solver.
%\end{itemize}
