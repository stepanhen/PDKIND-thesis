\chapter{Implementation}
\noindent In this chapter, we will refer to the description of the PDKind algorithm, analyze it and modify it to fit our implementation.

\section{Reachability checking procedure}
The reachability procedure, shown in \ref{alg:1} is a procedure, which determines whether a given state is reachable in a specific number of steps from a set of initial states. This check is completed using a depth-first search (DFS) strategy, along with other methods and data structures that need to be analyzed to ensure correctness and efficiency in our implementation.

The choice of depth-first search (DFS) in this procedure balances efficiency and memory usage. While DFS minimizes memory overhead compared to breadth-first search (BFS), it may explore deeper infeasible paths first, potentially increasing runtime in cases where a shallower counterexample exists.

The above-mentioned methods and data structures, that need analysis are: \textbf{Satisfiability checking}, \textbf{Generalization}, \textbf{Explanation} and \textbf{Reachability frames representation}.
\section*{Satisfiability Checking}
\noindent We could use various SMT solvers for satisfiability checking, including Z3\cite{10.1007/978-3-540-78800-3_24}, CVC5\cite{10.1007/978-3-030-99524-9_24}, or OpenSMT\cite{10.1007/978-3-642-12002-2_12}, with each solver having different strengths in terms of efficiency, theory support, or integration capabilities.

Since Golem already provides a wrapper around the OpenSMT solver and uses it for satisfiability checking in every other engine, we also chose it for our implementation. This choice maintains consistency across the whole project and avoids problems of integrating a new solver into the project.

Another reason for using OpenSMT is that since it is used in all other Golem engines, it provides a fair performance comparison of these engines with our PDKind engine. Using a different SMT solver in our implementation could give our engine an advantage or a disadvantage in terms of efficiency. By using OpenSMT, we ensure that these possibilities are isolated and that the observed performance differences would come mainly from algorithmic strength rather than solver efficiency.

Furthermore, OpenSMT provides utilities that are very important for our engine. One of them is providing models for satisfiability checks, and the other is the ability to generate interpolants. Since interpolation is used to strengthen inductive invariants, utilizing these features eliminates the need for additional mechanism implementation. While other SMT solvers may offer similar capabilities, choosing OpenSMT is the most convenient and efficient choice for our implementation.

\section*{Generalization}

\noindent Generalization plays an essential role in PDKind by preventing redundant checks and improving abstraction. It ensures that the algorithm abstracts wider state representation rather than handling individual states separately. However, Golem does not provide a built-in generalization method.

Still, it has needed components to create our method, as shown in pseudocode Algorithm \ref{alg:2}. The method uses the KeepOnly function to eliminate all non-state variables from the formula \( T[B]^k(\vec{x}, \vec{w}, \vec{y}) \wedge C(\vec{y}) \), retaining only the state variables $\vec{x}$. We will show that this approach satisfies the generalization definition \ref{generalization}.

\begin{figure}[H]
    \begin{mdframed}
        \begin{algorithmic}[1]
            \State \textbf{Input:} Model $M$, transition formula $T$, state formula $F$
            \State \textbf{Output:} Generalized formula $G$

            \State $StateVars \gets$ GetStateVars()
            \State $G \gets$ KeepOnly(StateVars, $T \wedge F$, $M$)
            \State \Return $G$

        \end{algorithmic}
    \end{mdframed}
    \caption{Generalize method}\label{alg:2}
\end{figure}

\subsection*{Relationship between $M$, $T$ and $F$}
\noindent In algorithm \ref{alg:2}, we use three formulas:
\begin{itemize}
    \item \textbf{$T$ (Transition formula)}: Defines the evolution of states over time.
    \item \textbf{$F$ (State formula)}: Represents the state that we are analyzing.
    \item \textbf{$M$ (Model)}: A satisfying assignment to formula $T \land F$ that provides an example of a state transition.
\end{itemize}

Given a model $M$, our goal is to abstract it into a formula $G$ that describes a wider set of possible states.

\subsection*{KeepOnly method}
\noindent The KeepOnly method extracts only the state variables from $T \land G$ by removing all the auxiliary variables, such as the intermediate states $\vec{w}$ and the successor states $\vec{y}$ from definition \ref{generalization}. This approach ensures that the generalized formula $G$ depends only on the current state $\vec{x}$, which makes the formula $G(\vec{x})$ an over-approximation as it represents all possible states that satisfy $T \land F$ rather than just the single assignment given by model $M$.

\subsection*{Satisfying the Generalization Definition}
\noindent To confirm that Algorithm \ref{alg:2} correctly implements generalization, we check the two required properties:

\newpage
\begin{enumerate}
    \item\textbf{Over-approximation}:
    \begin{itemize}
        \item By removing $\vec{w}, \vec{y}$, we ensure that $G(\vec{x})$ captures all possible satisfying assignments for the transition relation $T$ and condition $F$.
        \item This directly satisfies the first condition of the generalization definition \ref{generalization}.
    \end{itemize}
    \item\textbf{Consistency with Initial States $A(\vec{x})$}:
    \begin{itemize}
        \item Since we only eliminate intermediate variables and do not introduce new constraints, $G(\vec{x})$ remains consistent with the original set of reachable states.
        \item This ensures that $G(\vec{x})$ does not eliminate any valid states from consideration.
    \end{itemize}
\end{enumerate}
Thus, algorithm \ref{alg:2} produces a valid and useful generalization for PDKind.

\section*{Explanation} \label{Explain}
\noindent Instead of implementing a custom \( Explain() \) method, we utilize the OpenSMT solver feature, which is an interpolation. To obtain the interpolant, we tell the solver to compute an interpolation of the first two formulas inserted in it. For example, given a satisfiability check $CheckSat(A \land B \land C)$, we want an interpolant of $A \land B$.

Interpolation is useful here because it provides a formula that separates $A \land B$ from $C$, ensuring that the learned constraints eliminate infeasible states without being too restrictive.

On line 13 in Algorithm \ref{alg:1}, we require an interpolant from the \( CheckSAT() \) call that occurred in the previous \( Reachable() \) call. To support this behavior, we modify our \( Reachable() \) method on line 17 to return an interpolant along with the \( false \) result when a check fails. Since interpolation is only defined when the formula is unsatisfiable, we only request an interpolant if \( CheckSAT() \) returns \( false \).

In our implementation, each \( CheckSAT() \) is performed using a separate solver instance. This means obtaining an interpolant is simple; we instruct the solver instance to return the interpolant generated from its internal state, reflecting the formulas used in the failed check.

\section*{Reachability frames representation}\label{RFrames}
\noindent For the \( Reachability frames \) representation, we had several choices. The simplest approach was to create a list $R$ of formulas, where each frame is stored as $R_i := R[i]$. Each time we call \( Reachable() \) from outside, we would construct a new list of reachability frames.

While this method is straightforward, it is inefficient because it discards previously computed frames with each call, preventing reuse and requiring redundant computation. Instead, we create a more efficient approach by making a \( Reachability \) class.

Each instance of the \( Reachability \) class  maintains a persistent list of frames, where calling \( Reachable() \) on that instance extends the existing reachability frames instead of discarding them. This allows us to reuse previously computed information across multiple calls, improving efficiency and reducing unnecessary recomputation.

\section{Push}
\section*{Induction frame}
\noindent Induction frame is a key data structure in the PDKind algorithm. It is used to store lemmas lead to creating inductive invariants.

In our implementation, we represent the \( Induction Frame \) as a set of objects, where each object consists of:
\begin{itemize}
    \item A lemma, representing an inductive candidate formula.
    \item A counterexample structure, which stores additional information about the counterexample.
\end{itemize}
We choose to store the counterexample in a different structure, which allows us to keep not only the counterexample formula but also the number of steps needed to reach it from the initial states. This additional data is crucial for generating unsatisfiability witnesses when proving an \( UNSAFE \) property.

\section*{Extended Reachable method}
\noindent We previously mentioned that OpenSMT\cite{OpenSMT} provides the option to retrieve a model after a successful satisfiability check. Since OpenSMT does not return models by default, we initialize a new solver instance for each satisfiability check. This ensures that model extraction remains independent for each query and avoids unintended side effects when performing multiple checks.

On line 19, we see that \( Reachable() \) accepts more arguments and returns more values than shown in Algorithm \ref{alg:1}. The extended method $Reachable(i, j, F)$ now checks whether \( F \) is reachable within \( k \) steps, where \( i \leq k \leq j \).

To implement this behavior, we create a wrapper function that iterates over possible values of \( k \), calling $Reachable(k, F)$ in a loop. The function returns the first \( k \) where reachability is successful, along with the result.

If none of the calls succeed, instead of returning just \( false \) result, we extract an interpolant from the final \( Reachable() \) check. This allows us to refine our constraints even in cases where reachability fails, improving the overall efficiency of the algorithm.

While this approach ensures correctness, initializing a new solver instance for each check introduces some performance overhead. However, since each \( CheckSAT() \) call operates independently, this trade-off is necessary to maintain solver consistency. Similarly, iterating over multiple values of \( k \) increases computational effort but allows us to efficiently find the earliest reachable step, which improves overall precision.


\section{PDKind}
\noindent In our implementation, the property \( P \) is defined as the negation of a query, that
we get on the input, which represents a set of bad states. This transformation ensures that proving \( P \) invariant is equivalent to proving that the original query is never reachable.

Before running the main loop of PDKind, we perform two initial checks:
\begin{enumerate}
    \item\textbf{Are the initial states empty?} If there are no initial states, the system is then trivially safe, and so we return \( SAFE \).
    \item\textbf{Does the query hold in the initial states?} If the query already holds in the initial states, the system is immediately unsafe, and we return \( UNSAFE \).
\end{enumerate}

If neither of these conditions is met, the algorithm continues with an iterative process which calls \( Push() \) procedure to find a k-inductive strengthening of \( P \) .

The method continues until it either finds a k-inductive invariant (proving safety) or discovers a counterexample (proving unsafety).
\section{Validity checking}
\noindent In many cases, it is often required to provide a witness to the
answer obtained from solving the CHC satisfiability problem. In software
verification, a satisfiability witness corresponds to a program invariant, and
an unsatisfiability witness corresponds to counterexample paths. Generally, a
satisfiability witness is a model that provides an interpretation of all CHC
predicates and variables that satisfy all the clauses. An unsatisfiability
witness is a proof presented as a sequence of derivations of ground instances
of the predicates, where for the proof to be valid, each premise must be a
conclusion of some previously derived step.

Witnesses are essential in formal verification, as they provide concrete evidence to support the solver's conclusion, ensuring that verification results are both explainable and reproducible.

In Golem \cite{blicha_golem_2023}, each engine provides a validity witness when
the option \texttt{--print-witness} is used. To follow the structure Golem has,
we need to implement such an option for our PDKind engine as well.

\section*{UNSAT witness} \label{UNSATWit}
\noindent First, we will describe the implementation of the unsatisfiability
witness in our engine. The goal is to generate paths to counterexamples during
the CHC satisfiability solving process.

To generate counterexample paths, we utilize a function in the Golem solver, which computes the
path to a counterexample based on the number of steps required to reach the
counterexample.

Instead of storing complete counterexample traces, we only keep track of the number of steps needed
to reach counterexample for each potential counterexample we encounter during the CHC
solving. The number of steps a potential counterexample
is a number of steps needed to reach the counterexample from the potential
counterexample. To do this, we take the \( Induction frame \)
\( (lemma, counterExample) \) and create a structure for the
\( counterExample \), which will hold the formula and the number of steps to reach the
counterxample.

In the next step, we need to correctly assign the number of steps to a
counterexample to each potential counterexample, that we find. In Algorithm
\ref{alg:3}, we note that a new counterexample
$g_2$ is created only on line 18, which we then use in the else branch
starting on line 23. The number of steps to a counterexample assigned to
$g_2$ is the number of steps to a counterexample in $counterExample$ incremented by \( k \).

Finally, we need to modify \( Push() \) procedure to return the number of steps to a
counterexample. On line 21, when we encounter a reachable counterexample
$g_2$, we assign the steps to a counterexample returned by
the \( Push() \) procedure to be the number of steps to a counterexample of $g_2$.

\section*{SAT witness}
\noindent In this section, we will describe the implementation of the
satisfiability witness in the PDKind engine. The aim is to construct an
inductive invariant during the CHC satisfiability solving process.

In the $Push()$ procedure described in Algorithm
\ref{alg:3}, we construct an \\ 
\(Induction Frame\), which is a set of tuples \((lemma, counterExample)\), where the
\( lemma \) holds for \( n \) steps and refutes the
\( counterExample \). After the solving procedure is finished, we end up on
line 12 of the PDKind procedure in Algorithm \ref{alg:4}
because we are constructing the satisfiability
witness. We can then take the final \( Induction Frame \) and form a
conjunction of all the lemmas within it. This gives us an \( n \)-inductive
invariant, as the lemmas hold for \( n \) steps, and there is no other
strengthening of the \( Induction Frame \), as indicated by \( F = G \) at
line 11.

The final step is to transform the n-inductive invariant into an inductive
invariant. To do that, we utilize the Golem solver's function
\( kinductiveToInductive() \), which takes the \( n \)-inductive invariant,
\( n \), and the system and returns an inductive invariant. This invariant
is the validity witness for the \( SAT \) answer.

